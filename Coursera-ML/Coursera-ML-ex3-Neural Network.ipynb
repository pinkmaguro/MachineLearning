{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "import scipy.io\n",
    "import random\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addOnes(X):\n",
    "    m = X.shape[0]\n",
    "    ones = np.ones(m)\n",
    "    onesX = np.column_stack((ones, X))\n",
    "    return onesX\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def initTheta(n, option=0):\n",
    "    theta= np.zeros(n)\n",
    "    if option != 0:\n",
    "        theta = np.random.random(n)\n",
    "    return theta.reshape(-1,1)\n",
    "\n",
    "def computeCostLog(theta, X, y, lamda = 0.):\n",
    "    X = addOnes(X)\n",
    "    m = X.shape[0]\n",
    "    y = y.reshape(-1,1)\n",
    "    \n",
    "    theta = theta.reshape(-1,1)\n",
    "    theta0 = np.copy(theta); theta[0] = 0;\n",
    "    \n",
    "    h = sigmoid(X @ theta)\n",
    "    J =  - y.T @ log(h) - (1- y).T @ log(1-h) + (lamda / 2) * theta0.T @ theta0\n",
    "    J = J / (1.0 * m)\n",
    "    return J[0,0]\n",
    "\n",
    "def computeGradLog(theta, X, y, lamda = 0.):\n",
    "    X = addOnes(X)\n",
    "    m = X.shape[0]\n",
    "    y = y.reshape(-1,1)\n",
    "    \n",
    "    theta = theta.reshape(-1,1)\n",
    "    theta0 = np.copy(theta); theta[0] = 0;\n",
    "    \n",
    "    h = sigmoid(X @ theta)\n",
    "    grad =  (X.T @ (h - y)) + lamda * theta0\n",
    "    grad = grad / (1.0 * m)\n",
    "    grad = grad.ravel()\n",
    "    return grad\n",
    "\n",
    "def gradientDescentLog(X, y,lamda = 0., alpha = 0.01, numIter = 1500, seed = 0):\n",
    "    X = addOnes(X)\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    y = y.reshape(-1,1)\n",
    "    theta = initTheta(n, seed)\n",
    "    theta0 = np.copy(theta); theta[0] = 0;\n",
    "    \n",
    "    J = np.zeros(numIter)\n",
    "    for i in range(0, numIter):\n",
    "        h = sigmoid(X @ theta)\n",
    "        cost =  (1.0/m) * ((- y.T @ log(h) - (1- y).T @ log(1-h)) + (lamda / 2) * theta0.T @ theta0 )\n",
    "        J[i] = cost[0]\n",
    "\n",
    "        gradient =  (1.0/m) * ((X.T @ (h - y)) + lamda * theta0)\n",
    "        theta = theta - alpha * gradient\n",
    "    theta = theta.ravel()\n",
    "    return (theta, J[-1], J)\n",
    "\n",
    "def predict(theta, X):\n",
    "    X = addOnes(X)\n",
    "    h = sigmoid(X @ theta)\n",
    "    threshold = 0.5\n",
    "    predict = (h > threshold).astype(int)\n",
    "    return predict\n",
    "\n",
    "def accuracy(theta, X, y):\n",
    "    p = predict(theta, X)\n",
    "    compare = np.equal(p.reshape(1,-1),y.reshape(1,-1)).astype(int)\n",
    "    accuracy = np.mean(compare)\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "def plot2D(X, y):\n",
    "    pos = np.where(y == 1)\n",
    "    neg = np.where(y == 0)\n",
    "    plt.scatter(X[pos, 0], X[pos, 1], marker='+', c='b')\n",
    "    plt.scatter(X[neg, 0], X[neg, 1], marker='o', c='y')\n",
    "    plt.show()\n",
    "    \n",
    "def plot2DLog(theta, X, y):\n",
    "    pos = np.where(y == 1)\n",
    "    neg = np.where(y == 0)\n",
    "    plt.scatter(X[pos, 0], X[pos, 1], marker='+', c='b')\n",
    "    plt.scatter(X[neg, 0], X[neg, 1], marker='o', c='y')\n",
    "    x_lin = np.linspace(np.min(X[:,0]) , np.max(X[:,0]), 100)\n",
    "    plt.plot(x_lin, - (x_lin * theta[1] + theta[0])/theta[2])\n",
    "    plt.show()\n",
    "    \n",
    "def plotPolyMesh2DLog(X, y, p, C=1e5):\n",
    "    poly = PolynomialFeatures(p)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    logreg = linear_model.LogisticRegression(C=C)\n",
    "    logreg.fit(X_poly,y.ravel())\n",
    "\n",
    "    theta3 = np.append(logreg.intercept_, logreg.coef_)\n",
    "    \n",
    "    pts = 200\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, pts), np.linspace(y_min, y_max, pts))\n",
    "    Z = logreg.predict( poly.fit_transform(np.c_[xx.ravel(), yy.ravel()])[:,:]  )\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(1, figsize=(4, 4))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "    plt.xlabel('1')\n",
    "    plt.ylabel('2')\n",
    "\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def predictOneVsAll(all_theta, X):\n",
    "    m = X.shape[0]\n",
    "    num_labels = all_theta.shape[0]\n",
    "    X = addOnes(X)\n",
    "    predict = (X @ all_theta.T).argmax(1)\n",
    "    return predict\n",
    "\n",
    "def accuracyOneVsAll(all_theta, X, y):\n",
    "    p = predictOneVsAll(all_theta, X)\n",
    "    compare = np.equal(p.reshape(1,-1), y.reshape(1,-1)).astype(int)\n",
    "    accuracy = np.mean(compare)  \n",
    "    return accuracy\n",
    "\n",
    "def predictNN(theta1, theta2, X):\n",
    "    m = X.shape[0]\n",
    "    num_labelsels = theta2.shape[0]\n",
    "    \n",
    "    Theta1 = theta1.T\n",
    "    Theta2 = theta2.T\n",
    "    \n",
    "    a1 = X\n",
    "    \n",
    "    z1 = addOnes(a1) @ Theta1\n",
    "    \n",
    "    a2 = sigmoid(z1)\n",
    "    \n",
    "    z2 = addOnes(a2) @ Theta2\n",
    "    \n",
    "    a3 = sigmoid(z2)\n",
    "    \n",
    "    predict = a3.argmax(1)\n",
    "    \n",
    "    return predict\n",
    "\n",
    "def accuracyNN(theta1, theta2, X, y):\n",
    "    p = predictNN(theta1, theta2, X)\n",
    "    compare = np.equal(p.reshape(1,-1), y.reshape(1,-1)).astype(int)\n",
    "    accuracy = np.mean(compare)  \n",
    "    return accuracy\n",
    "\n",
    "def accuracyNN(theta1, theta2, X, y):\n",
    "    p = predictNN(theta1, theta2, X)\n",
    "    compare = np.equal(p.reshape(1,-1), y.reshape(1,-1)).astype(int)\n",
    "    accuracy = np.mean(compare)  \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('X', (5000, 400), 'double'), ('y', (5000, 1), 'double')]\n",
      "(5000, 400)\n",
      "(5000, 1)\n",
      "[('Theta1', (25, 401), 'double'), ('Theta2', (10, 26), 'double')]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "input_layer_size  = 400;\n",
    "hidden_layer_size = 25; \n",
    "num_labels = 10; \n",
    "\n",
    "file = r'../data/ex3data1.mat'\n",
    "print(scipy.io.whosmat(file))    # inspect what kinds of data the file has\n",
    "mat = scipy.io.loadmat(file)\n",
    "X = mat['X']; print(X.shape)\n",
    "y = mat['y']; print(y.shape)\n",
    "y = y - 1   # original y data ranges from 1 to 10.\n",
    "\n",
    "file2 = r'../data/ex3weights.mat'\n",
    "print(scipy.io.whosmat(file2))    # inspect what kinds of data the file has\n",
    "mat2 = scipy.io.loadmat(file2)\n",
    "theta1 = mat2['Theta1']\n",
    "theta2 = mat2['Theta2']\n",
    "\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9752\n"
     ]
    }
   ],
   "source": [
    "print(accuracyNN(theta1, theta2, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=25, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(25), random_state=1)\n",
    "\n",
    "clf.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X)\n",
    "print(pred.shape)\n",
    "print(np.unique(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare = np.equal(pred.reshape(1,-1), y.reshape(1,-1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 4000\n",
    "end = start + 100\n",
    "print(pred[start:end])\n",
    "print(y[start:end].ravel())\n",
    "\n",
    "np.mean(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log, sum\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addOnes(X):    \n",
    "    m = X.shape[0]\n",
    "    ones = np.ones(m)\n",
    "    onesX = np.column_stack((ones, X))\n",
    "    return onesX\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoidGradient(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_lables, X, y, lambda_):\n",
    "    theta1 = nn_params[:(input_layer_size + 1) * hidden_layer_size].reshpe(hidden_layer_size, (input_layer_size + 1))\n",
    "    theta2 = nn_params[(input_layer_size + 1) * hidden_layer_size:].reshpe(num_lables, (hidden_layer_size + 1))\n",
    "    m = X.shape[0]\n",
    "    J = 0\n",
    "    \n",
    "    a1 = addOnes(X)\n",
    "    z2 = a1 @ theta1.T\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = a2 @ theta2.T\n",
    "    a3 = sigmoid(z3)\n",
    "    h_X = a3\n",
    "    \n",
    "    yVec = np.zeros((m, num_lables))\n",
    "    for i in range(m):\n",
    "        yVec[i, y[i]] = 1\n",
    "    \n",
    "    J =  (1.0/m) * sum(sum (-1 * yVec * log(h_X)  - (1 - yVec) * log(1-h_X)))\n",
    "    regularator = (lambda_/(2.0*m)) * (sum(sum(theta1[:,1:] ** 2)) + sum(sum(Theta2[:,1:] ** 2))) ;\n",
    "    J += regularator\n",
    "\n",
    "    delta_3 = a3 - yVec\n",
    "    delta_2 = (theta2.T @ delta_3) * sigmoidGradient(z2)\n",
    "        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19661193,  0.25      ,  0.19661193])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoidGradient(np.array([-1,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x8191d68>,\n",
       " <matplotlib.lines.Line2D at 0x8191f28>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_lin = np.linspace(-10,10,200)\n",
    "\n",
    "plt.plot(x_lin, sigmoid(x_lin), x_lin, sigmoidGradient(x_lin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.weights = []\n",
    "    # layers = [2,2,1]\n",
    "        for i in range(1, len(layers)):\n",
    "            r = 2*np.random.random((layers[i], layers[i - 1] + 1))\n",
    "            self.weights.append(r)\n",
    "        \n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=3000):\n",
    "        X = addOnes(X)\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "            for l in range(len(self.weights)):\n",
    "                dot_value = self.weights[l] @ (np.hstack((1, a)))\n",
    "                activation = sigmoid(dot_value)\n",
    "                a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * sigmoidGradient(a[-1])]\n",
    "            \n",
    "            for l in range(len(a) - 2, 0, -1):\n",
    "                deltas.append(weights[l].T * sigmoidGradient(a[l]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-09ae1a5e2d82>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-09ae1a5e2d82>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    for\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = list()\n",
    "    theta1 = 0.1 * np.random.random((n_hidden, n_inputs + 1))\n",
    "    network.append(theta1)\n",
    "    theta2 = 0.1 * np.random.random((n_outputs, n_hidden + 1))\n",
    "    network.append(theta2)\n",
    "    return network\n",
    "\n",
    "def activate(weights, inputs):\n",
    "    pass\n",
    "\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers, weights=None):\n",
    "        \"\"\"\n",
    "        layers = [2,2,1]\n",
    "        \"\"\"\n",
    "        self.activation = sigmoid\n",
    "        self.activation_prime = sigmoid_prime\n",
    "        if not weights:\n",
    "            self.weights = []\n",
    "        #self.weights = [np.array([[1, 0.1, 0.1],[1, 0.1, 0.1]]),\n",
    "        #               np.array([[1, 0.1, 0.1],[1, 0.1, 0.1]])]\n",
    "            for i in range(1, len(layers)):\n",
    "                r = np.random.random((layers[i], layers[i - 1] + 1)) - 0.5\n",
    "                self.weights.append(r)\n",
    "        else:\n",
    "            self.weights = weights\n",
    "        print('weights', self.weights)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.5, epochs=3000):\n",
    "\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "        \n",
    "            for l in range(len(self.weights)):\n",
    "                a_in = self.weights[l] @ np.insert(a[l],0,1)\n",
    "                activation = self.activation(a_in)\n",
    "                a.append(activation)\n",
    "            #print('a', a)\n",
    "\n",
    "            error = y[i] - a[-1]\n",
    "            #print('error',error)\n",
    "            outer_delta = self.activation_prime(a[-1]) * (-error)\n",
    "            deltas = [outer_delta]\n",
    "            for l in range(len(a) - 2, 0, -1):\n",
    "               # print(a[l].shape)\n",
    "               # print(self.weights[l].T.shape)\n",
    "               # print(deltas[len(a) - 2 - l].shape)\n",
    "                delta = np.insert(self.activation_prime(a[l]),0,1) * (self.weights[l].T @ deltas[len(a) - 2 - l])\n",
    "                delta = delta[1:]\n",
    "                deltas.append(delta)\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas = np.flip(deltas, axis=0)\n",
    "            #print('deltas', deltas)\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            \n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(np.insert(a[i],0,1))\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                #print(layer.T.shape)\n",
    "                #print(delta.shape)\n",
    "                #print(self.weights[i].shape)\n",
    "                self.weights[i] -= learning_rate * (delta.T @ layer)\n",
    "\n",
    "            #print('weigts', self.weights)\n",
    "\n",
    "    def predict(self, x): \n",
    "        a = x\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = np.insert(a, 0, 1)\n",
    "            a = self.activation(self.weights[l] @ a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [array([[-0.47170372, -0.39499153,  0.25275224]])]\n",
      "[ 0.03403878]\n",
      "[ 0.20134578]\n",
      "[ 0.2008464]\n",
      "[ 0.64260903]\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([2,1])\n",
    "X = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])\n",
    "y = np.array([0,0,0,1]).reshape((-1,1))\n",
    "\n",
    "nn.fit(X, y,learning_rate=0.02,epochs=10000)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(nn.predict(X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [array([[-0.19517903,  0.30926319,  0.35154771],\n",
      "       [-0.26391903,  0.19896394, -0.06243876]]), array([[ 0.01235975, -0.04505517,  0.18647049],\n",
      "       [ 0.43150065,  0.27274992, -0.09220811]])]\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([2,2,2])\n",
    "X = np.array([[1,0]])\n",
    "y = np.array([[0, 1]])\n",
    "\n",
    "nn.fit(X, y,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
